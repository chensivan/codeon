{
  "contact": "NA",
  "question_id": "e69379cb-16a9-1420-6bfc-53d14783a359",
  "transcript": "",
  "changelog": [
    {
      "editorID": false,
      "type": "startRecording",
      "timestamp": 1455392820770
    },
    {
      "text": "var EventEmitter = require('events').EventEmitter;\nvar fse = require('fs-extra');\nvar fsp = require('fs-plus');\nvar fs = require('fs');\nvar jsonfile = require('jsonfile');\nvar util = require('util');\nvar path = require('path');\nvar RecordingBarView = require('./RecordingBarView');\nvar STORAGE_DIRECTORY = path.join(__dirname,'recordings');\n\nvar CompositeDisposable, Notification, Notifications, ref;\nref = require('atom'), Notification = ref.Notification, CompositeDisposable = ref.CompositeDisposable;\n\n\nvar client = require('socket.io-client');\nvar socket = client.connect('http://localhost:3000');\n\n//\n//TODO: 2 conditions logic\n\n// if (this is the first time trigger this package)\n// \t\t1) check any updated responses\n//\t\t2) set socket on addNotification\n// else if (this is not the first time trigger this package)\n//\t\t1) listen as always\n\n\n// if (there is a data.json file)\n// \t\topen file\n//\t  load all the question objectsID, and their last response timestamp\n// \t\tsend the object ID and\n\nvar file = path.join(STORAGE_DIRECTORY,'data.json');\nvar reopen = true;\n\n\nsocket.on('addNotification', function(data) {\n\tconsole.log(\"client connected: \");\n\tconsole.log(data);\n\t//read file and see if the q-id is here\n\n\tvar uid = data.id;\n\tvar message;\n\tconsole.log(\"   fewafew\");\n\tvar obj = new Object();\n\tfs.stat(file, function(err, stat){\n\t\tif (err == null){\n\t\t\tobj = JSON.parse(fs.readFileSync(file, 'utf8'));\n\t\t\tconsole.log(obj);\n\n\t\t\tif(obj.hasOwnProperty(uid)){\n\t\t\t\tconsole.log();\n\t\t\t\tobj[uid].response.push(data.msg);\n\t\t\t\tatom.notifications.addSuccess(\"You received one response for this question:\\n \"+data.id\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t+\"\\n the response is: \"+data.msg);\n\t\t\t}\n\t\t}\n\t});\n\n});\n\n\nvar recorder = new EventEmitter();\n\nrecorder._recording = false;\nrecorder.start = function() {\n\tconsole.log(\"nice\");\n\tsocket.emit('reopen', function() {\n\t\t\tconsole.log(\"sure\");\n\t});\n\n\tif(!this.isRecording()) {\n\n\t\t// atom.notifications.addSuccess(\"Success: This is a successful notification\");\n\t\t// atom.notifications.addWarning(\"Warning: This is a good notification\");\n\t\t// atom.notifications.addError(\"Error: This is a good notification\");\n\t\t// atom.notifications.addInfo(\"Info: This is a good notification\");\n\t\t// var a = atom.notifications.getNotifications();\n\t\t// Notifications.addNotificationView(a[2]);\n\t\t// console.log(a[2]);\n\n\t\t//checking updates\n\t\tif (reopen){\n\n\t\t\tvar obj = new Object();\n\t\t\tfs.stat(file, function(err, stat){\n\t\t\t\t\tconsole.log(err);\n\t\t\t\t\tconsole.log(stat);\n\t\t\t\tif (err == null){\n\t\t\t\t\tconsole.log(\"some data\");\n\t\t\t\t\t// obj = JSON.parse(fs.readFileSync(file, 'utf8'));\n\t\t\t\t\t//\n\t\t\t\t\t// obj[uid] = {\n\t\t\t\t\t// \tid: uid,\n\t\t\t\t\t// \tresponse: []\n\t\t\t\t\t// }\n\t\t\t\t  // jsonfile.writeFile(file, obj, function (err) {\n\t\t\t\t  //   console.error(err)\n\t\t\t\t  // })\n\t\t\t\t}else if(err.code === 'ENOENT') {\n\t\t\t\t\tconsole.log(\"no data yet\");\n\t\t\t\t}else{\n\t\t\t\t\tconsole.log(\" some thing wrong\");\n\t\t\t\t}\n\t\t\t})\n\n\n\t\t\treopen = false;\n\t\t}\n\n\t\tthis.emit(\"start\");\n\t\tthis._recording = true;\n\t}\n};\nrecorder.stop = function() {\n\tif(this.isRecording()) {\n\t\tthis._recording = false;\n\t\tthis.emit(\"stop\");\n\t}\n};\nrecorder.cancel = function() {\n\tif(this.isRecording()) {\n\t\tthis._recording = false;\n\t\tthis.emit(\"cancel\");\n\t}\n};\nrecorder.isRecording = function() {\n\treturn this._recording;\n};\nrecorder.toggle = function() {\n\treturn this.isRecording() ? this.stop() : this.start();\n};\nrecorder.activate = function() {\n\trecordingBarView = new RecordingBarView();\n\n\trecordingBarView.$getElement().on('done', function() {\n\t\t\trecorder.stop();\n\t\t}).on('cancel', function() {\n\t\t\trecorder.cancel();\n\t\t});\n\tmodalPanel = atom.workspace.addTopPanel({\n\t\titem: recordingBarView.getElement(),\n\t\tvisible: false\n\t});\n\tatom.commands.add('atom-workspace', 'voice-assist:toggle', this.toggle.bind(this));\n};\nrecorder.deactivate = function() {\n\tif(modalPanel) {\n\t\tmodalPanel.destroy();\n\t\tmodalPanel = false;\n\t}\n\tthis.cancel();\n\tif(recordingBarView) {\n\t\trecordingBarView.destroy();\n\t}\n};\nrecorder.serialize = function() {\n\treturn {};\n};\nrecorder.config = {\n\tuploadURL: {\n\t\ttitle: 'Upload URL',\n\n\t\t// default: 'http://107.170.177.159:3000/upload_recording',\n\t\tdefault: 'http://localhost:3000/upload_recording',\n\n\t\t// default: 'http://107.170.177.159:3000/upload_recording',\n\t\t//default: 'http://localhost:3000/upload_recording',\n\n\t\ttype: 'string'\n\t},\n\tcontactinfo: {\n\t\ttitle: 'Skype Username',\n\t\tdefault: 'NA',\n\t\ttype: 'string'\n\t}\n};\n\nvar recordingBarView;\nvar voiceRecorder = require('./voiceRecorder');\nvar editorRecorder = require('./editorRecorder');\nvar workspaceSnapshot = require('./workspaceSnapshot');\nvar uploadRecording = require('./uploadRecording');\nvar modalPanel;\nvar uid;\nvar cwd;\n\nrecorder.on('start', function() {\n\tuid = guid();\n\n\tvar obj = new Object();\n\tfs.stat(file, function(err, stat){\n\t\t\tconsole.log(err);\n\t\t\tconsole.log(stat);\n\t\tif (err == null){\n\t\t\tobj = JSON.parse(fs.readFileSync(file, 'utf8'));\n\t\t\tobj[uid] = {\n\t\t\t\tid: uid,\n\t\t\t\tresponse: []\n\t\t\t}\n\t\t  jsonfile.writeFile(file, obj, function (err) {\n\t\t    console.error(err)\n\t\t  })\n\t\t}else if(err.code === 'ENOENT') {\n\t\t\tobj[uid] = {\n\t\t\t\t\t\tid: uid,\n\t\t\t\t\t\tresponse: []\n\t\t\t\t\t}\n\t\t\tconsole.log(\"ok\");\n\t\t  jsonfile.writeFile(file, obj, function (err) {\n\t\t    console.error(err)\n\t\t  })\n\t\t}else{\n\t\t\tconsole.log(\" some thing wrong\");\n\t\t}\n\t})\n\n\n\tcwd = workspaceSnapshot.start(uid);\n\tvoiceRecorder.start(uid);\n\teditorRecorder.start(uid, cwd);\n\tmodalPanel.show();\n}).on('stop', function() {\n\tmodalPanel.hide();\n\tuploadRecording(uid, editorRecorder, voiceRecorder, workspaceSnapshot, cwd);\n}).on('cancel', function() {\n\teditorRecorder.cancel(uid);\n\tvoiceRecorder.cancel(uid);\n\tworkspaceSnapshot.cancel(uid);\n\tmodalPanel.hide();\n\n\tvar folder = STORAGE_DIRECTORY + uid + '/';\n\tfse.remove(folder, function() {\n\t\tconsole.log(\"done\");\n\t});\n});\nfunction guid() {\n\tfunction s4() {\n\t\treturn Math\t.floor((1 + Math.random()) * 0x10000)\n\t\t\t\t\t.toString(16)\n\t\t\t\t\t.substring(1);\n\t}\n\treturn s4() + s4() + '-' + s4() + '-' + s4() + '-' +\n\t\t\ts4() + '-' + s4() + s4() + s4();\n}\n\nmodule.exports = recorder;\n",
      "path": "lib/voice-assist.js",
      "editor": {
        "deserializer": "TextEditor",
        "id": 410,
        "softTabs": false,
        "scrollRow": 112,
        "displayBuffer": {
          "deserializer": "DisplayBuffer",
          "id": 411,
          "softWrapped": false,
          "tokenizedBuffer": {
            "deserializer": "TokenizedBuffer",
            "bufferPath": "/Users/yanchen/dev/voice-assist/lib/voice-assist.js",
            "largeFileMode": false
          },
          "largeFileMode": false
        }
      },
      "topRow": 112,
      "active": true,
      "editorID": 410,
      "type": "start",
      "timestamp": 1455392820770
    },
    {
      "text": "var _ = require('./vendor/underscore'),\n\tRecordRTC = require('recordrtc'),\n\tfs = require('fs'),\n\tmkdirp = require('./mkdirp');\n//\n\n\nvar RECORDING_STORAGE_DIRECTORY = __dirname + '/recordings/';\n\nvar recognitionEngine = new webkitSpeechRecognition();\nrecognitionEngine.continue = true;\nrecognitionEngine.interimResults = false;\nrecognitionEngine.maxResults = 1;\n\nfunction getUserMedia() {\n\treturn new Promise(function(resolve, reject) {\n\t\ttry {\n\t\t\tnavigator.webkitGetUserMedia({\n\t\t\t\taudio: true\n\t\t\t}, function(audioStream) {\n\t\t\t\tresolve(audioStream);\n\t\t\t}, function(err) {\n\t\t\t\treject(err);\n\t\t\t});\n\t\t} catch (e) {\n\t\t\treject(\"Your browser does not support WebRTC. Please try the latest version of Chrome.\");\n\t\t}\n\t});\n}\n\nvar transcriptPromise, audioStreamPromise, recorder;\nvar question_id;\nvar stopped = false;\nvar transcriptResult;\n\nmodule.exports = {\n\tstart: function (uid) {\n\t\ttranscriptResult = '';\n\t\tstopped = false;\n\t\tquestion_id = uid;\n\n\t\ttranscriptPromise = new Promise(function(resolve, reject) {\n\t\t\trecognitionEngine.start();\n\t\t\trecognitionEngine.onresult = function(event) {\n\t\t\t\tvar results = event.results,\n\t\t\t\t\tmostLikelyResult = results[0][0].transcript;\n\t\t\t\ttranscriptResult += mostLikelyResult;\n\t\t\t\tif(stopped) {\n\t\t\t\t\tresolve(transcriptResult);\n\t\t\t\t}\n\t\t\t};\n\t\t\trecognitionEngine.onend = function() {\n\t\t\t\t_.delay(function() {\n\t\t\t\t\tresolve(transcriptResult);\n\t\t\t\t}, 3000);\n\t\t\t}\n\t\t});\n\t\taudioStreamPromise = getUserMedia().then(function(audioStream) {\n\t\t\trecorder = RecordRTC(audioStream);\n\t\t\trecorder.startRecording();\n\t\t\treturn audioStream;\n\t\t});\n\t},\n\tstop: function(uid) {\n\t\tstopped = true;\n\t\trecognitionEngine.stop();\n\t\tvar wavPromise = audioStreamPromise.then(function(audioStream) {\n\t\t\t\t\t\t\treturn new Promise(function(resolve, reject) {\n\t\t\t\t\t\t\t\trecorder.stopRecording(function() {\n\t\t\t\t\t\t\t\t\tresolve(recorder.getBlob());\n\t\t\t\t\t\t\t\t});\n\t\t\t\t\t\t\t\taudioStream.stop();\n\t\t\t\t\t\t\t});\n\t\t\t\t\t\t}).then(function(blob) {\n\t\t\t\t\t\t\treturn new Promise(function(resolve, reject) {\n\t\t\t\t\t\t\t\tvar fr = new FileReader();\n\t\t\t\t\t\t\t\tfr.addEventListener(\"loadend\", function() {\n\t\t\t\t\t\t\t\t\tresolve(fr.result);\n\n\t\t\t\t\t\t\t\t})\n\t\t\t\t\t\t\t\tfr.readAsBinaryString(blob);\n\t\t\t\t\t\t\t});\n\t\t\t\t\t\t}).then(function(binaryContent) {\n\t\t\t\t\t\t\tvar folder = RECORDING_STORAGE_DIRECTORY + uid + '/',\n\t\t\t\t\t\t\t\tfilename =  'audio.wav',\n\t\t\t\t\t\t\t\tfullFilename = folder  + filename;\n\n\t\t\t\t\t\t\treturn mkdirp(folder).then(function() {\n\t\t\t\t\t\t\t\t\treturn new Promise(function(resolve, reject) {\n\t\t\t\t\t\t\t\t\t\tfs.writeFile(fullFilename, binaryContent, \"binary\", function(err) {\n\t\t\t\t\t\t\t\t\t\t\tif(err) {\n\t\t\t\t\t\t\t\t\t\t\t\treject(err);\n\t\t\t\t\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\t\t\t\t\tresolve(fullFilename);\n\t\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t\t});\n\t\t\t\t\t\t\t\t\t});\n\t\t\t\t\t\t\t\t});\n\t\t\t\t\t\t});\n\n\t\treturn {\n\t\t\ttranscript: transcriptPromise,\n\t\t\twav: wavPromise\n\t\t};\n\t},\n\tcancel: function() {\n\t\trecognitionEngine.abort();\n\t\taudioStreamPromise.then(function(audioStream) {\n\t\t\taudioStream.stop();\n\t\t});\n\t}\n}\n",
      "path": "lib/voiceRecorder.js",
      "editor": {
        "deserializer": "TextEditor",
        "id": 500,
        "softTabs": false,
        "displayBuffer": {
          "deserializer": "DisplayBuffer",
          "id": 501,
          "softWrapped": false,
          "tokenizedBuffer": {
            "deserializer": "TokenizedBuffer",
            "bufferPath": "/Users/yanchen/dev/voice-assist/lib/voiceRecorder.js",
            "largeFileMode": false
          },
          "largeFileMode": false
        }
      },
      "active": false,
      "editorID": 500,
      "type": "start",
      "timestamp": 1455392820771
    },
    {
      "text": "<body ng-controller='MainController'>\n\t<!--<canvas id=\"pie\" class=\"chart chart-pie\" chart-data=\"data\" chart-labels=\"labels\"\n    chart-legend=\"true\" chart-series=\"series\" chart-click=\"onClick\"></canvas>-->\n\n\t<h1>Atom Language Information</h1>\n\t<div ng-controller=\"SuggestedExamplesController\">\n\t\t<h1 ng-if='examples'>Suggested Code</h1>\n\t\t<div ng-click='importExample(example)' ng-repeat='example in examples'>\n\t\t\t<h2>{{example.description}}</h2>\n\t\t\t<div hljs hljs-source='example.code' />\n\t\t</div>\n\t</div>\n</body>",
      "path": "views/main.view.html",
      "editor": {
        "deserializer": "TextEditor",
        "id": 478,
        "softTabs": false,
        "displayBuffer": {
          "deserializer": "DisplayBuffer",
          "id": 479,
          "softWrapped": false,
          "tokenizedBuffer": {
            "deserializer": "TokenizedBuffer",
            "bufferPath": "/Users/yanchen/dev/voice-assist/views/main.view.html",
            "largeFileMode": false
          },
          "largeFileMode": false
        }
      },
      "active": false,
      "editorID": 478,
      "type": "start",
      "timestamp": 1455392820771
    },
    {
      "text": "module.exports = function(app) {\n\t// see http://jtblin.github.io/angular-chart.js/\n\tapp.factory('ServerQuery', ['$http', function ($http) {\n\t    var serverURL = atom.config.get('atom-lang-viz.serverURL');\n\t\tvar lastChar = serverURL.substr(-1); // Selects the last character\n\t\tif (lastChar != '/') {         // If the last character is not a slash\n\t\t\tserverURL = serverURL + '/';            // Append a slash to it.\n\t\t}\n\n\t\treturn {\n\t\t\trunQuery: function(selectedText) {\n\t\t\t\treturn $http({\n\t\t\t\t\tmethod: 'GET',\n\t\t\t\t\turl: serverURL,\n\t\t\t\t\tparams: {\n\t\t\t\t\t\tquery: selectedText\n\t\t\t\t\t}\n\t\t\t\t}).then(function(fullResponse) {\n\t\t\t\t\treturn fullResponse;\n\t\t\t\t}, function(err) {\n\t\t\t\t\tconsole.error(err);\n\t\t\t\t});\n\t\t\t},\n\t\t\tgetSuggestedExampleCode: function(language, description) {\n\t\t\t\treturn $http({\n\t\t\t\t\tmethod: 'GET',\n\t\t\t\t\turl: serverURL+'sampleCode',\n\t\t\t\t\tparams: {\n\t\t\t\t\t\tlanguage: language,\n\t\t\t\t\t\tdescription: description\n\t\t\t\t\t}\n\t\t\t\t}).then(function(response) {\n\t\t\t\t\treturn response.data;\n\t\t\t\t});\n\t\t\t}\n\t\t};\n\t}]);\n};\n",
      "path": "services/server_query.js",
      "editor": {
        "deserializer": "TextEditor",
        "id": 486,
        "softTabs": false,
        "scrollRow": 0,
        "displayBuffer": {
          "deserializer": "DisplayBuffer",
          "id": 487,
          "softWrapped": false,
          "tokenizedBuffer": {
            "deserializer": "TokenizedBuffer",
            "bufferPath": "/Users/yanchen/dev/voice-assist/services/server_query.js",
            "largeFileMode": false
          },
          "largeFileMode": false
        }
      },
      "active": false,
      "editorID": 486,
      "type": "start",
      "timestamp": 1455392820772
    },
    {
      "text": "# Keybindings require three things to be fully defined: A selector that is\n# matched against the focused element, the keystroke and the command to\n# execute.\n#\n# Below is a basic keybinding which registers on all platforms by applying to\n# the root workspace element.\n\n# For more detailed documentation see\n# https://atom.io/docs/latest/behind-atom-keymaps-in-depth\n'atom-workspace':\n  'cmd-shift-e': 'voice-assist:toggle'\n  'cmd-shift-v': 'atom-lang-viz:toggle'\n",
      "path": "keymaps/voice-assist.cson",
      "editor": {
        "deserializer": "TextEditor",
        "id": 466,
        "softTabs": true,
        "displayBuffer": {
          "deserializer": "DisplayBuffer",
          "id": 467,
          "softWrapped": false,
          "tokenizedBuffer": {
            "deserializer": "TokenizedBuffer",
            "bufferPath": "/Users/yanchen/dev/voice-assist/keymaps/voice-assist.cson",
            "largeFileMode": false
          },
          "largeFileMode": false
        }
      },
      "active": false,
      "editorID": 466,
      "type": "start",
      "timestamp": 1455392820772
    },
    {
      "text": "var VizView = require('./viz-view');\n//MAIN ATOM FILE\nmodule.exports = {\n\tactivate: function(state) {\n\t\tthis.enabled = !!state.enabled;\n\n\t\t//this.parser = new Parser();\n\t\tthis.vizView = new VizView(this.enabled);\n\n\t\tatom.commands.add('atom-workspace', 'atom-lang-viz:toggle', this.toggle.bind(this));\n\t},\n\tdeactivate: function() {\n\t\t//this.parser.destroy();\n\t\tthis.vizView.destroy();\n\t},\n\tserialize: function() {\n\t\treturn {\n\t\t\tenabled: this.enabled\n\t\t};\n\t},\n\ttoggle: function() {\n\t\tthis.enabled = !this.enabled;\n\t\tthis.vizView.enable(this.enabled);\n\t},\n\tconfig: {\n\t\tserverURL: {\n\t\t\ttype: 'string',\n\t\t\tdefault: 'http://localhost:3000/'\n\t\t}\n\t}\n};\n",
      "path": "lib/atom-lang-viz.js",
      "editor": {
        "deserializer": "TextEditor",
        "id": 490,
        "softTabs": false,
        "displayBuffer": {
          "deserializer": "DisplayBuffer",
          "id": 491,
          "softWrapped": false,
          "tokenizedBuffer": {
            "deserializer": "TokenizedBuffer",
            "bufferPath": "/Users/yanchen/dev/voice-assist/lib/atom-lang-viz.js",
            "largeFileMode": false
          },
          "largeFileMode": false
        }
      },
      "active": false,
      "editorID": 490,
      "type": "start",
      "timestamp": 1455392820773
    },
    {
      "editorID": false,
      "type": "stopRecording",
      "timestamp": 1455392823252
    }
  ],
  "cwd": "/Users/yanchen/dev/voice-assist"
}
